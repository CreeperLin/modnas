search:
  data:
    type: 'CIFAR10'
    # type: 'MNIST'
    # type: 'ImageNet'
    train_root: './data'
    valid_root: './data'
    dloader:
      type: 'pytorch'
      split_ratio: 0 # not splitting data (one level)
      trn_batch_size: 64
      val_batch_size: 64
      workers: 2
      cutout: 0
      jitter: True
  estimator:
    search:
      type: 'SuperNet'
      w_optim:
        type: 'sgd'
        args:
          lr: 0.025
          momentum: 0.9
          weight_decay: 0.0003
          nesterov: True
      lr_scheduler:
        type: 'cosine'
        args:
          eta_min: 0.001
      aux_weight: 0.0
      drop_path_prob: 0.0
      w_grad_clip: 5.
      epochs: 50
      print_freq: 200
      save_freq: 25
      plot: False
      arch_update_epoch_start: 0
      arch_update_epoch_intv: 1
      arch_update_intv: -1
      arch_update_batch: 1
arch_optim:
  type: 'Dummy'
  a_optim:
    type: 'adam'
    args:
      lr: 0.0003
      betas: [0.5, 0.999]
      weight_decay: 0.001
mixed_op:
  type: 'WeightedSum'
ops:
  ops_order: 'act_weight_bn'
  affine: False
criterion:
  type: 'LS'
  eta: 0.1
model:
  type: 'DARTS'
  classes: 10             # use 10 for MNIST, CIFAR10
  channel_in: 3           # 3 for ImageNet/CIFAR10, 1 for MNIST
  channel_init: 16        # init channel
  channel_multiplier: 3   # init channel multiplier
  nodes: 4                # num of nodes (states) per layer
  layers: 8               # num of DAG layers (cells) in model
  inputs_model: 1
  inputs_layer: 2
  inputs_node: 1
  shared_a: True
  auxiliary: False
primitives:
  - 'AVG'
  - 'MAX'
  - 'SC3'
  - 'SC5'
  - 'DC3'
  - 'DC5'
  - 'IDT'
  - 'NIL'
log:
  writer: False
device:
  gpus: 'all'
  seed: 2
genotypes:
  gt_str: ''
  gt_path: ''
init:
  type: 'he_normal_fout'