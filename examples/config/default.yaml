search:
  data:
    type: 'CIFAR10'
    # type: 'MNIST'
    # type: 'ImageNet'
    train_root: './data'
    valid_root: './data'
    dloader:
      type: 'pytorch'
      split_ratio: 0.8
      trn_batch_size: 64
      val_batch_size: 64
      workers: 2
      cutout: 0
      jitter: True
  estimator:
    search:
      type: 'SuperNet'
      w_optim:
        type: 'sgd'
        args:
          lr: 0.035
          momentum: 0.9
          nesterov: True
          weight_decay: 0.0001
        # type: 'adabound'
        # lr: 0.001
        # final_lr: 0.05
      lr_scheduler:
        type: 'cosine'
        args:
          eta_min: 0.001
      aux_weight: 0.0
      w_grad_clip: 0.0
      drop_path_prob: 0.0
      warmup_epochs: 30
      epochs: 200
      print_freq: 200
      save_freq: 100
      arch_update_epoch_start: 0
      arch_update_epoch_intv: 1
      arch_update_intv: -1
      arch_update_batch: 1
augment:
  data:
    type: 'CIFAR10'
    # type: 'MNIST'
    # type: 'ImageNet'
    train_root: './data'
    valid_root: './data'
    dloader:
      type: 'pytorch'
      split_ratio: 0
      trn_batch_size: 64
      val_batch_size: 64
      workers: 2
      cutout: 16
      jitter: True
  estimator:
    train:
      type: 'Default'
      epochs: 600
      w_optim:
        type: 'sgd'
        args:
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          nesterov: True
      lr_scheduler:
        type: 'cosine'
        args:
          eta_min: 0.001
      aux_weight: 0.0
      drop_path_prob: 0.0
      w_grad_clip: 0.0
      print_freq: 200
      save_freq: 300
arch_optim:
  type: 'BinGate'
  n_samples: 0
  batch_size: 10
  w_momentum: 0.9
  w_weight_decay: 0.0003
  renorm: True
  a_optim:
    type: 'adam'
    args:
      lr: 0.006
      betas: [0.0, 0.999]
      weight_decay: 0
mixed_op:
  type: 'BinGate'
ops:
  ops_order: 'bn_act_weight'
  affine: False
criterion:
  type: 'LS'
  eta: 0.1
model:
  type: 'ProxylessNAS'
  classes: 10             # use 10 for MNIST, CIFAR10
  channel_in: 3           # 3 for ImageNet/CIFAR10, 1 for MNIST
  channel_init: 16        # init channel
  channel_multiplier: 1   # init channel multiplier
  groups: 3               # num of nodes (states) per layer
  blocks: 18              # num of DAG layers (cells) in model
  alpha: 84
  nodes: 4                # num of nodes (states) per layer
  layers: 8              # num of DAG layers (cells) in model
  inputs_model: 1
  inputs_layer: 2
  inputs_node: 1
  conv_groups: 2
  bottleneck_ratio: 4
  path_drop_rate: 0.0
  dropout_rate: 0.0
  use_avg: False
  bn_before_add: True
  pxl_ops_order: 'bn_act_weight'
  auxiliary: False
  shared_a: True
primitives:
  - 'AVG'
  - 'MAX'
  - 'IDT'
  - 'SS3'
  - 'SS5'
  - 'DC3'
  - 'DC5'
  - 'NIL'
log:
  writer: False
device:
  gpus: 'all'
  seed: 2
tune:
  tuner: 'Random'
genotypes:
  gt_str: ''
  gt_path: ''
init:
  type: 'he_normal_fout'