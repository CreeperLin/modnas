search:
  data:
    type: 'CIFAR10'
    train_root: './data'
    valid_root: './data'
    dloader:
      type: 'pytorch'
      split_ratio: 0
      size: 0.01
      trn_batch_size: 4
      val_batch_size: 4
      workers: 0
      cutout: 0
      jitter: False
  estimator:
    supernet:
      type: 'SuperNet'
      w_optim:
        type: 'sgd'
        args:
          lr: 0.035
          momentum: 0.9
          nesterov: False
          weight_decay: 0.0001
      lr_scheduler:
        type: 'cosine'
        args:
          eta_min: 0.0
      aux_weight: 0.0
      w_grad_clip: 0.0
      drop_path_prob: 0.0
      epochs: 3
      print_freq: 200
      save_freq: 0
      arch_update_epoch_start: 0
      arch_update_epoch_intv: 1
      arch_update_intv: -1
      arch_update_batch: 1
      # plot: False
arch_optim:
  type: 'DirectGrad'
  a_optim:
    type: 'adam'
    args:
      lr: 0.006
      betas: [0.0, 0.999]
      weight_decay: 0.0
mixed_op:
  type: 'BinGateUniform'
  primitives:
    - 'SC3'
    - 'SC5'
    - 'SC7'
    - 'NC3'
    - 'NC5'
    - 'NC7'
    - 'DC3'
    - 'DC5'
ops:
  ops_order: 'weight'
  affine: False
criterion:
  type: 'LS'
  eta: 0.1
model:
  type: 'CIFAR-resnet-50'
  classes: 10             # use 10 for MNIST, CIFAR10
  channel_in: 3           # 3 for ImageNet/CIFAR10, 1 for MNIST
  channel_init: 16        # init channel
log:
  writer: False
device:
  gpus: 'all'
  seed: 2
tune:
  tuner: 'Random'
genotypes:
  gt_str: ''
  gt_path: ''
init:
  type: 'he_normal_fout'