search:
  data:
    type: 'CIFAR10'
    # type: 'MNIST'
    # type: 'ImageNet'
    train_root: './data'
    valid_root: './data'
    dloader:
      type: 'pytorch'
      size: 0.002
      split_ratio: 0.8
      trn_batch_size: 4
      val_batch_size: 4
      workers: 0
      cutout: 0
      jitter: False
  estimator:
    warmup:
      type: 'Default'
      w_optim:
        type: 'sgd'
        args:
          lr: 0.1
          momentum: 0.9
          nesterov: True
          weight_decay: 0.0001
      lr_scheduler:
        type: 'cosine'
        args:
          eta_min: 0.001
      w_grad_clip: 0.0
      drop_path_prob: 0.0
      epochs: 1
      print_freq: 200
      save_freq: 0
      aux_weight: 0.0
    subnet:
      # type: 'SuperNet'
      type: 'SubNet'
      w_optim:
        type: 'sgd'
        args:
          lr: 0.035
          momentum: 0.9
          nesterov: True
          weight_decay: 0.0001
        # type: 'adabound'
        # lr: 0.001
        # final_lr: 0.05
      lr_scheduler:
        type: 'cosine'
        args:
          eta_min: 0.0
      w_grad_clip: 0.0
      drop_path_prob: 0.0
      epochs: 3
      subnet_epochs: 1
      print_freq: 200
      save_freq: 0
      arch_update_epoch_start: 0
      arch_update_epoch_intv: 1
      # arch_update_intv: -1
      # arch_update_batch: 1
      plot: False
      aux_weight: 0.0
      init:
        type: 'he_normal_fout'
optim:
  type: 'Random'
mixed_op:
  type: 'Index'
  primitives:
    - 'SC1'
    - 'SC3'
    - 'SC5'
    - 'SC7'
    - 'SC9'
ops:
  ops_order: 'bn_act_weight'
  affine: False
criterion:
  type: 'CE'
model:
  type: 'TestNet'
  args:
    n_classes: 10             # use 10 for MNIST, CIFAR10
    chn_in: 3           # 3 for ImageNet/CIFAR10, 1 for MNIST
    chn: 16        # init channel
log:
  writer: False
device:
  gpus: 'all'
  seed: 2
genotypes:
  gt_str: ''
  gt_path: ''
init:
  type: 'he_normal_fout'